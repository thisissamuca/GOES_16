{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/lwo+2XThqCZVLnPvf+NC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thisissamuca/GOES_16/blob/main/GET_MASK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Usado para obter a máscara de nuvem reclassificada a partir do produto ABI-L2-ACMF"
      ],
      "metadata": {
        "id": "P9zlmrUYdj-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xarray rasterio affine satpy netCDF4 affine cartopy"
      ],
      "metadata": {
        "id": "w5H4zVPl0Tes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Montando drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WaxvS70NdG8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ead2e0fc-99a1-4ddc-8fee-8b21f1fc4b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Máscara de nuvem reclassificada"
      ],
      "metadata": {
        "id": "DnlbcYOn3Iu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from affine import Affine\n",
        "import os\n",
        "import netCDF4\n",
        "import cv2\n",
        "import cartopy.crs\n",
        "import numpy as np\n",
        "import xarray as xr\n",
        "import rasterio\n",
        "from satpy import Scene\n",
        "from typing import List, Dict, Optional, Generator\n",
        "import warnings\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import time\n",
        "\n",
        "# Configuração para suprimir avisos não essenciais\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class NetCDFBatchProcessor:\n",
        "    \"\"\"Classe para processamento em lote de arquivos NetCDF com dados de satélite.\"\"\"\n",
        "\n",
        "    def __init__(self, base_path: str = '/content/drive/MyDrive/NBR/ARQUIVOS_BRUTOS'): # Pasta de arquivos que armazena os produtos ACMF\n",
        "        self.base_path = base_path\n",
        "\n",
        "    def list_product_files(self, product: str) -> List[str]:\n",
        "        \"\"\"Lista todos os arquivos disponíveis para um produto específico.\"\"\"\n",
        "        product_path = os.path.join(self.base_path, product, 'netCDF')\n",
        "        return sorted([f for f in os.listdir(product_path) if f.endswith('.nc')])\n",
        "\n",
        "    def get_variables(self, product: str, filename: str) -> Dict[int, str]:\n",
        "        \"\"\"Retorna um dicionário com as variáveis disponíveis em um arquivo NetCDF.\"\"\"\n",
        "        file_path = os.path.join(self.base_path, product, 'netCDF', filename)\n",
        "\n",
        "        with netCDF4.Dataset(file_path) as dataset:\n",
        "            variables = {i: var for i, var in enumerate(dataset.variables.keys())}\n",
        "\n",
        "        return variables\n",
        "\n",
        "    def load_dataset(self, product: str, filename: str) -> xr.Dataset:\n",
        "        \"\"\"Carrega um arquivo NetCDF como xarray Dataset.\"\"\"\n",
        "        file_path = os.path.join(self.base_path, product, 'netCDF', filename)\n",
        "        return xr.open_dataset(file_path)\n",
        "\n",
        "class ImageBatchProcessor:\n",
        "    \"\"\"Classe para processamento em lote de imagens derivadas de dados de satélite.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def reclassify_array(data: np.ndarray, mapping: Dict[int, int]) -> np.ndarray:\n",
        "        \"\"\"Reclassifica um array numpy baseado em um dicionário de mapeamento (versão otimizada).\"\"\"\n",
        "        # Versão otimizada usando np.where para melhor desempenho\n",
        "        result = np.zeros_like(data, dtype=np.float32)\n",
        "        for key, value in mapping.items():\n",
        "            result = np.where(data == key, value, result)\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def safe_convert_to_float(data: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Converte valores do array para float de forma segura (versão vetorizada).\"\"\"\n",
        "        # Versão otimizada usando vectorize com cache\n",
        "        float_func = np.vectorize(lambda x: float(x) if isinstance(x, (int, float)) else np.nan,\n",
        "                                otypes=[np.float32])\n",
        "        return float_func(data)\n",
        "\n",
        "    @staticmethod\n",
        "    def resize_image(image: np.ndarray, target_shape: tuple = (5424, 5424)) -> np.ndarray:\n",
        "        \"\"\"Redimensiona imagem mantendo proporções (usando interpolação bilinear).\"\"\"\n",
        "        return cv2.resize(image, target_shape, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "class GeoTIFFBatchExporter:\n",
        "    \"\"\"Classe para exportação em lote de dados para formato GeoTIFF.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def create_transform(area) -> Affine:\n",
        "        \"\"\"Cria transformação afim a partir da área de dados.\"\"\"\n",
        "        res_x = area.pixel_size_x\n",
        "        res_y = -area.pixel_size_y\n",
        "        xmin, ymax = area.area_extent[0], area.area_extent[3]\n",
        "        return Affine.translation(xmin, ymax) * Affine.scale(res_x, res_y)\n",
        "\n",
        "    @staticmethod\n",
        "    def export_to_geotiff(data: np.ndarray, crs, transform, output_path: str):\n",
        "        \"\"\"Exporta array numpy para arquivo GeoTIFF.\"\"\"\n",
        "        profile = {\n",
        "            'driver': 'GTiff',\n",
        "            'height': data.shape[0],\n",
        "            'width': data.shape[1],\n",
        "            'count': 1,\n",
        "            'dtype': data.dtype,\n",
        "            'crs': crs,\n",
        "            'transform': transform,\n",
        "            'compress': 'lzw',  # Adicionado compressão para reduzir tamanho dos arquivos\n",
        "            'tiled': True      # Melhora performance para arquivos grandes\n",
        "        }\n",
        "\n",
        "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "        with rasterio.open(output_path, 'w', **profile) as dst:\n",
        "            dst.write(data, 1)\n",
        "\n",
        "def process_single_file(ncdf_processor, img_processor, exporter, product: str, filename: str,\n",
        "                       reclass_map: Dict, target_shape: tuple, output_dir: str):\n",
        "    \"\"\"Processa um único arquivo NetCDF e exporta para GeoTIFF.\"\"\"\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Carrega e processa os dados\n",
        "        ds = ncdf_processor.load_dataset(product, filename)\n",
        "        first_var = list(ds.variables.keys())[0]\n",
        "        variable_data = ds[first_var].data\n",
        "\n",
        "        # Processamento da imagem\n",
        "        reclassified = img_processor.reclassify_array(variable_data, reclass_map)\n",
        "        float_array = img_processor.safe_convert_to_float(reclassified)\n",
        "        resized_image = img_processor.resize_image(float_array, target_shape)\n",
        "\n",
        "        # Configuração do sistema de coordenadas\n",
        "        file_path = os.path.join(ncdf_processor.base_path, product, 'netCDF', filename)\n",
        "        scn = Scene(filenames=[file_path], reader='abi_l2_nc')\n",
        "        scn.load(['BCM'])\n",
        "\n",
        "        area = scn['BCM'].attrs['area']\n",
        "        transform = exporter.create_transform(area)\n",
        "        crs = area.to_cartopy_crs()\n",
        "\n",
        "        # Gera nome do arquivo de saída\n",
        "        output_filename = f\"{os.path.splitext(filename)[0]}_RECLASSIFIED.tif\"\n",
        "        output_path = os.path.join(output_dir, output_filename)\n",
        "\n",
        "        # Exportação\n",
        "        exporter.export_to_geotiff(resized_image, crs, transform, output_path)\n",
        "\n",
        "        processing_time = time.time() - start_time\n",
        "        return (filename, True, processing_time)\n",
        "\n",
        "    except Exception as e:\n",
        "        return (filename, False, str(e))\n",
        "\n",
        "def batch_process_files(product: str, output_dir: str, max_workers: int = 4):\n",
        "    \"\"\"Processa todos os arquivos de um produto em paralelo.\"\"\"\n",
        "    # Configurações\n",
        "    RECLASS_MAP = {1: 0, 0: 1}\n",
        "    TARGET_SHAPE = (5424, 5424)\n",
        "\n",
        "    # Inicialização dos processadores\n",
        "    ncdf_processor = NetCDFBatchProcessor()\n",
        "    img_processor = ImageBatchProcessor()\n",
        "    exporter = GeoTIFFBatchExporter()\n",
        "\n",
        "    # Obtém lista de arquivos\n",
        "    files = ncdf_processor.list_product_files(product)\n",
        "    if not files:\n",
        "        raise FileNotFoundError(f\"Nenhum arquivo encontrado para o produto {product}\")\n",
        "\n",
        "    print(f\"Iniciando processamento de {len(files)} arquivos...\")\n",
        "\n",
        "    # Cria diretório de saída se não existir\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Processamento em paralelo\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        futures = []\n",
        "        for filename in files:\n",
        "            future = executor.submit(\n",
        "                process_single_file,\n",
        "                ncdf_processor,\n",
        "                img_processor,\n",
        "                exporter,\n",
        "                product,\n",
        "                filename,\n",
        "                RECLASS_MAP,\n",
        "                TARGET_SHAPE,\n",
        "                output_dir\n",
        "            )\n",
        "            futures.append(future)\n",
        "\n",
        "        # Monitora progresso e resultados\n",
        "        success_count = 0\n",
        "        for future in as_completed(futures):\n",
        "            filename, status, result = future.result()\n",
        "            if status is True:\n",
        "                print(f\"Arquivo {filename} processado com sucesso em {result:.2f} segundos\")\n",
        "                success_count += 1\n",
        "            else:\n",
        "                print(f\"Erro ao processar {filename}: {result}\")\n",
        "\n",
        "    print(f\"\\nProcessamento concluído! {success_count}/{len(files)} arquivos processados com sucesso.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Configurações para execução\n",
        "    PRODUCT = \"ABI-L2-ACMF\"\n",
        "    OUTPUT_DIR = \"/content/drive/MyDrive/NBR/ARQUIVOS_PROCESSADOS/MASCARA_RECLASSIFICADA\"\n",
        "    MAX_WORKERS = 1  # Ajuste conforme os recursos disponíveis\n",
        "\n",
        "    # Executa o processamento em lote\n",
        "    start_total = time.time()\n",
        "    batch_process_files(PRODUCT, OUTPUT_DIR, MAX_WORKERS)\n",
        "    total_time = time.time() - start_total\n",
        "\n",
        "    print(f\"\\nTempo total de processamento: {total_time:.2f} segundos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61W_ZD4KOCQ5",
        "outputId": "7ba01cb6-3371-4fec-8626-d49b1e528f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando processamento de 12 arquivos...\n",
            "Arquivo OR_ABI-L2-ACMF-M6_G16_s20201521300164_e20201521309472_c20201521310161.nc processado com sucesso em 14.93 segundos\n",
            "Arquivo OR_ABI-L2-ACMF-M6_G16_s20201521310164_e20201521319472_c20201521320225.nc processado com sucesso em 11.53 segundos\n",
            "Arquivo OR_ABI-L2-ACMF-M6_G16_s20201521320164_e20201521329472_c20201521330186.nc processado com sucesso em 11.59 segundos\n",
            "Arquivo OR_ABI-L2-ACMF-M6_G16_s20201521330164_e20201521339472_c20201521340226.nc processado com sucesso em 11.36 segundos\n",
            "Arquivo OR_ABI-L2-ACMF-M6_G16_s20201521340164_e20201521349471_c20201521350201.nc processado com sucesso em 10.15 segundos\n",
            "Arquivo OR_ABI-L2-ACMF-M6_G16_s20201521350164_e20201521359471_c20201521400228.nc processado com sucesso em 11.51 segundos\n",
            "Arquivo OR_ABI-L2-ACMF-M6_G16_s20201531300167_e20201531309475_c20201531310180.nc processado com sucesso em 11.48 segundos\n",
            "Arquivo OR_ABI-L2-ACMF-M6_G16_s20201531310167_e20201531319475_c20201531320232.nc processado com sucesso em 11.45 segundos\n",
            "Arquivo OR_ABI-L2-ACMF-M6_G16_s20201531320167_e20201531329475_c20201531330174.nc processado com sucesso em 11.38 segundos\n",
            "Arquivo OR_ABI-L2-ACMF-M6_G16_s20201531330167_e20201531339475_c20201531340208.nc processado com sucesso em 9.76 segundos\n",
            "Arquivo OR_ABI-L2-ACMF-M6_G16_s20201531340167_e20201531349475_c20201531350233.nc processado com sucesso em 15.25 segundos\n",
            "Arquivo OR_ABI-L2-ACMF-M6_G16_s20201531350167_e20201531359475_c20201531400209.nc processado com sucesso em 13.34 segundos\n",
            "\n",
            "Processamento concluído! 12/12 arquivos processados com sucesso.\n",
            "\n",
            "Tempo total de processamento: 143.85 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kiDqEylyLMmR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}